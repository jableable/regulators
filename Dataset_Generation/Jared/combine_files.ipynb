{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we combine all .csv files into the single file total_state_data.csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df1 = pd.read_csv('../../SharedData/dataset-generation-final/population-1990-2020-final.csv')\n",
    "df2 = pd.read_csv('../../SharedData/dataset-generation-final/monthly_emissions_1990_2024')\n",
    "df3 = pd.read_csv('../../SharedData/dataset-generation-final/monthly-weather-1990-2019-final.csv')\n",
    "df4 = pd.read_csv('../../SharedData/dataset-generation-final/gdp-1997-2023-final.csv')\n",
    "df5 = pd.read_csv('../../SharedData/dataset-generation-final/energy_final.csv')\n",
    "df6 = pd.read_csv('../../SharedData/dataset-generation-final/power_plant_count.csv')\n",
    "df7 = pd.read_csv('../../SharedData/dataset-generation/state-areas.csv')\n",
    "df8 = pd.read_csv('../../SharedData/dataset-generation-final/energy-by-source-final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these lists are used to fix abbreviations in state-areas.csv\n",
    "\n",
    "state_names = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \"Delaware\", \"Florida\", \"Georgia\",\n",
    "    \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\",\n",
    "    \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\",\n",
    "    \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\",\n",
    "    \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\"\n",
    "]\n",
    "\n",
    "abbreviations = [\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n",
    "    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "    \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "    \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "    \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"\n",
    "]\n",
    "name_dict = {state_names[i]:abbreviations[i] for i in range(len(state_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate indexing columns\n",
    "\n",
    "df1 = df1.drop('Unnamed: 0', axis=1)\n",
    "df4 = df4.drop('Unnamed: 0', axis=1)\n",
    "df6 = df6.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# remove duplicate year/month columns\n",
    "\n",
    "df6 = df6.drop(['year','month'], axis=1)\n",
    "df8 = df8.drop(['year','month'], axis=1)\n",
    "\n",
    "# fix datetime formatting\n",
    "\n",
    "df2['date'] = df2['date'].apply(pd.to_datetime)\n",
    "df2['date'] = df2['date'].dt.strftime('%Y-%m')\n",
    "\n",
    "# fix abbreviations in state-areas.csv and make it into a dict\n",
    "\n",
    "df7['state'] = df7['state'].map(name_dict)\n",
    "df7_dict = df7.set_index('state')['area'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the dfs on 'state' and 'date'\n",
    "\n",
    "total_df = df1.merge(df2, on=['state','date'], how='right').merge(df3, on=['state','date'], how='left').merge(df4, on=['state','date'], how='left').merge(df5, on=['state','date'], how='left').merge(df6, on=['state','date'], how='left').merge(df8,on=['state','date'], how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove DC (not a state), HI, AK (states with missing CO2 data)\n",
    "\n",
    "total_df = total_df[~total_df.state.isin(['DC','HI','AK'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix datetime formatting\n",
    "\n",
    "total_df['date']=pd.to_datetime(total_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for sq ft of each state to calculation population density\n",
    "\n",
    "total_df['state_sq_ft']= total_df['state'].map(df7_dict)\n",
    "\n",
    "# add columns for monthly/yearly population density\n",
    "\n",
    "total_df['monthly_pop_density']= total_df['state_sq_ft']/total_df['monthly_population']\n",
    "total_df['yearly_pop_density']= total_df['state_sq_ft']/total_df['yearly_population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for simple moving avg\n",
    "\n",
    "total_df['monthly_emissions_sma']= np.nan\n",
    "\n",
    "for state in abbreviations:\n",
    "    total_df.loc[total_df.state==state,'monthly_emissions_sma'] = total_df.loc[total_df.state==state,'monthly_emissions'].rolling(window=12).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the columns for readability\n",
    "\n",
    "total_df = total_df[['state', 'state_sq_ft', \n",
    "        'year', 'month', 'date', \n",
    "        'monthly_population', 'yearly_population', 'monthly_pop_density', 'yearly_pop_density',\n",
    "        'monthly_emissions', 'monthly_emissions_sma',\n",
    "        'prcp', 'snow', 'tavg', \n",
    "        'gdp_rel_2017', 'gdp_rel_2017_interp', 'yearly_gdp_rel_2017',  \n",
    "        'monthly_energy_prod', 'yearly_energy_prod',\n",
    "        'monthly_energy_use', 'yearly_energy_use',\n",
    "        'monthly_energy_flow', 'yearly_energy_flow',         \n",
    "        'monthly_num_plants', 'yearly_num_plants', \n",
    "        'monthly_energy_total', 'yearly_energy_total',\n",
    "        'monthly_energy_renew', 'yearly_energy_renew', 'monthly_renew_pct', 'yearly_renew_pct',       \n",
    "        'monthly_energy_fossil', 'yearly_energy_fossil', 'monthly_fossil_pct', 'yearly_fossil_pct' \n",
    "        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_csv('../../SharedData/total_state_data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
