{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we combine all .csv files into the single file total_state_data.csv\n",
    "# all .csv files to be combined should be placed in ./Data directory\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df1 = pd.read_csv('../../SharedData/dataset-generation-final/population-1990-2020-final.csv')\n",
    "df2 = pd.read_csv('../../SharedData/dataset-generation-final/monthly_emissions_1990_2024')\n",
    "df3 = pd.read_csv('../../SharedData/dataset-generation-final/monthly-weather-1990-2019-final.csv')\n",
    "df4 = pd.read_csv('../../SharedData/dataset-generation-final/gdp-1997-2023-final.csv')\n",
    "df5 = pd.read_csv('../../SharedData/dataset-generation-final/energy_final.csv')\n",
    "df6 = pd.read_csv('../../SharedData/dataset-generation-final/power_plant_count.csv')\n",
    "df7 = pd.read_csv('../../SharedData/dataset-generation/state-areas.csv')\n",
    "df8 = pd.read_csv('../../SharedData/dataset-generation-final/energy-by-source-final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_names = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \"Delaware\", \"Florida\", \"Georgia\",\n",
    "    \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\",\n",
    "    \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\",\n",
    "    \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\",\n",
    "    \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\"\n",
    "]\n",
    "\n",
    "abbreviations = [\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n",
    "    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "    \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "    \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "    \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"\n",
    "]\n",
    "name_dict = {state_names[i]:abbreviations[i] for i in range(len(state_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate indexing columns\n",
    "\n",
    "df1 = df1.drop('Unnamed: 0', axis=1)\n",
    "df4 = df4.drop('Unnamed: 0', axis=1)\n",
    "df6 = df6.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# remove duplicate year/month columns\n",
    "\n",
    "df6 = df6.drop(['year','month'], axis=1)\n",
    "df8 = df8.drop(['year','month'], axis=1)\n",
    "\n",
    "# fix datetime formatting\n",
    "\n",
    "df2['date'] = df2['date'].apply(pd.to_datetime)\n",
    "df2['date'] = df2['date'].dt.strftime('%Y-%m')\n",
    "\n",
    "# fix abbreviations in state-areas.csv and make it into a dict\n",
    "\n",
    "df7['state'] = df7['state'].map(name_dict)\n",
    "df7_dict = df7.set_index('state')['area'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = df1.merge(df2, on=['state','date'], how='right').merge(df3, on=['state','date'], how='left').merge(df4, on=['state','date'], how='left').merge(df5, on=['state','date'], how='left').merge(df6, on=['state','date'], how='left').merge(df8,on=['state','date'], how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['date']=pd.to_datetime(total_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for sq ft of each state\n",
    "\n",
    "total_df['state_sq_ft']= total_df['state'].map(df7_dict)\n",
    "\n",
    "# add columns for monthly/yearly population density\n",
    "\n",
    "total_df['monthly_pop_density']= total_df['state_sq_ft']/total_df['monthly_population']\n",
    "total_df['yearly_pop_density']= total_df['state_sq_ft']/total_df['yearly_population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_csv('../../SharedData/total_state_data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
