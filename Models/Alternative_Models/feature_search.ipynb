{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pysyncon import Dataprep, Synth, AugSynth\n",
    "import itertools\n",
    "import numpy as np\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All states:\n",
    "states = [\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n",
    "    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "    \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "    \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "    \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"\n",
    "]\n",
    "# States belonging to RGGI. Exclude VA here; it was only in RGGI for a short time\n",
    "# Connecticut, Delaware, Maine, Maryland, Massachusetts, New Hampshire, New Jersey, New York, Pennsylvania, Rhode Island, and Vermont \n",
    "rggi_states = [\"CT\", \"DE\", \"ME\", \"MD\", \"MA\", \"NH\", \"NJ\", \"NY\", \"PA\", \"RI\", \"VT\"]\n",
    "# States with cap-and-trade programs as well as AK and HI, which are of course outside the continental US.\n",
    "other_states = [\"CA\", \"AK\", \"HI\"]\n",
    "# States not belonging to RGGI or other cap-and-trade programs.\n",
    "# WA will be included here because its cap-and-trade program was not around until after 2020.\n",
    "control_states = list(set(states) - set(rggi_states) - set(other_states))\n",
    "\n",
    "# Verify all fifty states accounted for:\n",
    "assert(len(rggi_states) + len(control_states) + len(other_states) == 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataframe\n",
    "df = pd.read_csv(os.path.join(\"..\", \"..\", \"..\", \"SharedData\", \"total_state_data.csv\"))\n",
    "df.date = pd.to_datetime(df.date)\n",
    "df = df[(df.date.dt.year>=1990)&(df.date.dt.year<2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some per capita calculations:\n",
    "df['co2_per_capita']   = df['monthly_emissions']   / df['monthly_population']\n",
    "df['gdp_per_capita']   = df['gdp_rel_2017_interp'] / df['monthly_population']\n",
    "df['eprod_per_capita'] = df['monthly_energy_prod'] / df['monthly_population']\n",
    "df['eflow_per_capita'] = df['monthly_energy_flow'] / df['monthly_population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>AvgLossSyn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Features  AvgLossSyn\n",
       "0   [1, 2]           3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.DataFrame(data=[[[1,2],3]], columns=[\"Features\", \"AvgLossSyn\"],dtype='object')\n",
    "df_1.to_csv(\"test.csv\", columns=[\"Features\", \"AvgLossSyn\"])\n",
    "df_2 = pd.DataFrame(data=[[[4,5],6]], columns=[\"Features\", \"AvgLossSyn\"],dtype='object')\n",
    "# df_1 = df_1.astype('object')\n",
    "# df_1.loc[0, \"Features\"] = [1,2]\n",
    "# df_1.loc[0, \"AvgLossSyn\"] = 3\n",
    "# df_2 = pd.DataFrame({\"Features\":[1], \"AvgLossSyn\":[2]})\n",
    "df_3 = pd.concat([df_1,df_2])\n",
    "# df_1.to_csv(\"text.csv\")\n",
    "df_load = pd.read_csv(\"test.csv\", index_col=0)\n",
    "# df_load.loc[0,\"Features\"]\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_features_of_interest = ['monthly_emissions', 'prcp', 'snow', 'tavg', \n",
    "        'gdp_rel_2017_interp', 'monthly_energy_prod',\n",
    "       'monthly_energy_use', \n",
    "       'monthly_energy_flow', \n",
    "        'monthly_renew_pct', 'monthly_fossil_pct',\n",
    "       'monthly_pop_density', 'monthly_emissions_sma']\n",
    "\n",
    "def hyperFeatureSearch(numFeatures, filename):\n",
    "    scores_df = pd.DataFrame(columns=[\"Features\", \"AvgLossSyn\"])\n",
    "    scores_df = scores_df.astype('object')\n",
    "\n",
    "    # Choose features to test\n",
    "    for features in itertools.combinations(monthly_features_of_interest, numFeatures):\n",
    "    \n",
    "        # Loop over RGGI states\n",
    "        loss_array = np.zeros(len(rggi_states))\n",
    "        counter = 0\n",
    "        for state_id in [\"DE\", \"NY\", \"TX\"]:\n",
    "            # state_id = rggi_state \n",
    "            control_ids = list(set(control_states) - set([state_id]))\n",
    "            rggi_ids = list(set(rggi_states) - set([state_id]))\n",
    "\n",
    "            # Stop the notebook if something goes wrong\n",
    "            assert(state_id not in other_states)\n",
    "            assert(len(control_ids) + len(rggi_ids) + 1 == 50 - len(other_states))\n",
    "\n",
    "            # Do computations monthly\n",
    "            month_jumps = 1\n",
    "\n",
    "            # Set up ranges\n",
    "            UL = 2009\n",
    "            LL_TIME = 1991      # Time range over which to perform fit\n",
    "\n",
    "            preintervention_time_range = df.date[(df.date.dt.year>=LL_TIME)&(df.date.dt.year<UL)&(df.state==state_id)][::month_jumps]\n",
    "\n",
    "            years = pd.date_range(start='1997-06-01', end='2019-12-01', freq='MS').strftime('%Y-%m-%d').tolist()[::month_jumps]\n",
    "            \n",
    "            special_predictors = [(feature, preintervention_time_range, 'mean') for feature in features]\n",
    "            special_predictors.append((\"co2_per_capita\", preintervention_time_range, 'mean'))\n",
    "            \n",
    "            \n",
    "            dataprep_control = Dataprep(\n",
    "                foo=df,\n",
    "                predictors=[],\n",
    "                predictors_op=\"mean\",\n",
    "                time_predictors_prior=preintervention_time_range,\n",
    "                special_predictors=special_predictors,\n",
    "                dependent=\"co2_per_capita\",\n",
    "                unit_variable=\"state\",\n",
    "                time_variable=\"date\",\n",
    "                treatment_identifier=state_id,\n",
    "                controls_identifier= control_ids,\n",
    "                time_optimize_ssr=preintervention_time_range\n",
    "            )\n",
    "            \n",
    "            # Do a synthetic control fit to the data using control states\n",
    "            synth = Synth()\n",
    "\n",
    "            synth.fit(dataprep=dataprep_control)\n",
    "            # print(loss_array)\n",
    "            loss_array[counter] = synth.loss_V\n",
    "            counter += 1\n",
    "            \n",
    "        feature_avg_loss = np.average(loss_array)\n",
    "        result = pd.DataFrame(data=[[list(features),feature_avg_loss]], columns=[\"Features\", \"AvgLossSyn\"], dtype='object')\n",
    "        # result = result.astype('object')\n",
    "        # result.loc[\"Features\"] = list(features)\n",
    "        # result.loc[\"AvgLossSyn\"] = feature_avg_loss\n",
    "        scores_df = pd.concat([scores_df, result])\n",
    "        # print(scores_df)\n",
    "        \n",
    "    output = filename + \"_\" + str(numFeatures) + \".csv\"\n",
    "    scores_df.to_csv(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One done\n",
      "Two done\n",
      "Three done\n",
      "Four done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m hyperFeatureSearch(\u001b[32m4\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDE-NY-TX-91to09_scores\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFour done\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mhyperFeatureSearch\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDE-NY-TX-91to09_scores\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFive done\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mhyperFeatureSearch\u001b[39m\u001b[34m(numFeatures, filename)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Do a synthetic control fit to the data using control states\u001b[39;00m\n\u001b[32m     57\u001b[39m synth = Synth()\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43msynth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataprep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataprep_control\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# print(loss_array)\u001b[39;00m\n\u001b[32m     61\u001b[39m loss_array[counter] = synth.loss_V\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bluecat\\miniforge3\\envs\\regulators\\Lib\\site-packages\\pysyncon\\synth.py:176\u001b[39m, in \u001b[36mSynth.fit\u001b[39m\u001b[34m(self, dataprep, X0, X1, Z0, Z1, custom_V, optim_method, optim_initial, optim_options)\u001b[39m\n\u001b[32m    173\u001b[39m     loss_V = \u001b[38;5;28mself\u001b[39m.calc_loss_V(W=W, Z0=Z0_arr, Z1=Z1_arr)\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_V\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m res = \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptim_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptim_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m V_mat = np.diag(np.abs(res[\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m])) / np.sum(np.abs(res[\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m]))\n\u001b[32m    178\u001b[39m W, loss_W = \u001b[38;5;28mself\u001b[39m.w_optimize(V_mat=V_mat, X0=X0_arr, X1=X1_arr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bluecat\\miniforge3\\envs\\regulators\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:726\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    723\u001b[39m callback = _wrap_callback(callback, meth)\n\u001b[32m    725\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mnelder-mead\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m     res = \u001b[43m_minimize_neldermead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m                               \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mpowell\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    729\u001b[39m     res = _minimize_powell(fun, x0, args, callback, bounds, **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bluecat\\miniforge3\\envs\\regulators\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:914\u001b[39m, in \u001b[36m_minimize_neldermead\u001b[39m\u001b[34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, bounds, **unknown_options)\u001b[39m\n\u001b[32m    912\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m     ind = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfsim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    915\u001b[39m     sim = np.take(sim, ind, \u001b[32m0\u001b[39m)\n\u001b[32m    916\u001b[39m     fsim = np.take(fsim, ind, \u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bluecat\\miniforge3\\envs\\regulators\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:1243\u001b[39m, in \u001b[36margsort\u001b[39m\u001b[34m(a, axis, kind, order, stable)\u001b[39m\n\u001b[32m   1130\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[32m   1131\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34margsort\u001b[39m(a, axis=-\u001b[32m1\u001b[39m, kind=\u001b[38;5;28;01mNone\u001b[39;00m, order=\u001b[38;5;28;01mNone\u001b[39;00m, *, stable=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1132\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1133\u001b[39m \u001b[33;03m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[32m   1134\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1241\u001b[39m \n\u001b[32m   1242\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m        \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43margsort\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstable\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bluecat\\miniforge3\\envs\\regulators\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "hyperFeatureSearch(1, \"DE-NY-TX-91to09_scores\")\n",
    "print(\"One done\")\n",
    "hyperFeatureSearch(2, \"DE-NY-TX-91to09_scores\")\n",
    "print(\"Two done\")\n",
    "hyperFeatureSearch(3, \"DE-NY-TX-91to09_scores\")\n",
    "print(\"Three done\")\n",
    "hyperFeatureSearch(4, \"DE-NY-TX-91to09_scores\")\n",
    "print(\"Four done\")\n",
    "hyperFeatureSearch(5, \"DE-NY-TX-91to09_scores\")\n",
    "print(\"Five done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regulators",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
